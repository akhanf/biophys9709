{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akhanf/biophys9709/blob/2025/Lecture_8b_Autoencoders.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYHfkHjbSoRZ"
      },
      "source": [
        "## Boilerplate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTwnzRo640f1"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Autoencoder for dimensionality reduction"
      ],
      "metadata": {
        "id": "Pw_CgwprcMGE"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qk4z3FZLS1b1"
      },
      "source": [
        "## Load data\n",
        "\n",
        "Load MNIST data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIsTGNH-5LA0"
      },
      "source": [
        "# load and examine the data\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJ0hkGWaVO7E"
      },
      "source": [
        "## Pre-processing\n",
        "\n",
        "Perform the same pre-processing as the previous examples in class.\n",
        "Except, we use the input image as the class label."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rcV8yFQD7OI"
      },
      "source": [
        "# Keras needs the image tensors to have a channel dimension, even if there is only one channel, so we reshape the tensors accordingly.\n",
        "\n",
        "x_train = x_train.reshape(60000, 28, 28, 1)\n",
        "x_test = x_test.reshape(10000, 28, 28, 1)\n",
        "\n",
        "# Convert the pixels to float32 type.\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "# Rescale the pixel values to run from 0 to 1.\n",
        "x_train = x_train / 255\n",
        "x_test = x_test / 255\n",
        "\n",
        "#save the digit labels (for visualization)\n",
        "y_label_train = y_train\n",
        "y_label_test = y_test\n",
        "\n",
        "#use the input image as the class label (autoencoder)\n",
        "y_train =\n",
        "y_test =\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-f8FXj5fNyv"
      },
      "source": [
        "## Define hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b36Ebuo5d0Xc"
      },
      "source": [
        "#input shape:\n",
        "img_shape = (x_train.shape[1], x_train.shape[2], 1)\n",
        "\n",
        "# hyperparameters to define and train the model\n",
        "batch_size = 32\n",
        "epochs = 5\n",
        "val_split = 0.2\n",
        "\n",
        "#steps to cycle through entire dataset in an epoch\n",
        "steps_per_epoch = int(np.floor(x_train.shape[0] *(1-val_split)  /batch_size) )\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdX1oTxwkwa0"
      },
      "source": [
        "steps_per_epoch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7656g8V2x95"
      },
      "source": [
        "## Define the AutoEncoder network\n",
        "\n",
        "Build using fully-connected layers:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljIPnbBaUdCX"
      },
      "source": [
        "flat_shape = np.prod(img_shape)\n",
        "\n",
        "size_bottleneck =\n",
        "size_encode_decode =\n",
        "\n",
        "#we will define an encoder and decoder separately,\n",
        "# then connect them together\n",
        "\n",
        "\n",
        "#define layers of encoder\n",
        "\n",
        "#input layer\n",
        "input_layer = keras.layers.Input(img_shape)\n",
        "x = keras.layers.Flatten()(input_layer)\n",
        "\n",
        "#encoder layer\n",
        "x =\n",
        "\n",
        "#bottleneck layer\n",
        "encoded_layer =\n",
        "\n",
        "\n",
        "#define layers of decoder\n",
        "encoded_shape = (size_bottleneck,)\n",
        "encoded_input = keras.layers.Input(encoded_shape)\n",
        "\n",
        "#decoder layer:\n",
        "x =\n",
        "\n",
        "\n",
        "#output layer:\n",
        "x = keras.layers.Dense(flat_shape, activation='sigmoid')(x)\n",
        "output_layer = keras.layers.Reshape(img_shape)(x)\n",
        "\n",
        "#define the models:\n",
        "encoder = keras.Model(input_layer,encoded_layer)\n",
        "decoder = keras.Model(encoded_input,output_layer)\n",
        "\n",
        "#define autoencoder from input layer to output of decoder\n",
        "autoencoder = keras.Model(input_layer, decoder(encoded_layer))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFPRDP4kfpA1"
      },
      "source": [
        "# Compile the model\n",
        "loss = keras.losses.mean_squared_error\n",
        "optim = keras.optimizers.Adam()\n",
        "metric = keras.metrics.mean_squared_error\n",
        "\n",
        "autoencoder.compile(loss=loss,\n",
        "                    optimizer=optim,\n",
        "                    metrics=metric )\n",
        "\n",
        "# What does the finished model look like?\n",
        "autoencoder.summary()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder.summary()\n",
        "print('encoder:')\n",
        "keras.utils.plot_model(encoder, show_shapes=True, rankdir='LR')\n"
      ],
      "metadata": {
        "id": "w7IJxJvZLS0i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoder.summary()\n",
        "print('decoder:')\n",
        "keras.utils.plot_model(decoder, show_shapes=True, rankdir='LR')"
      ],
      "metadata": {
        "id": "XjfzxYn9LR6T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3IxGLRZnenlI"
      },
      "source": [
        "## Train the network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7SXwJoalgWhw"
      },
      "source": [
        "#fit the model\n",
        "history = autoencoder.fit(x_train,y_train,\n",
        "            batch_size=batch_size,\n",
        "            validation_split=val_split,\n",
        "            epochs=epochs,\n",
        "            steps_per_epoch=steps_per_epoch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFtC11t-esFY"
      },
      "source": [
        "## Plot the loss & metric over training epochs and test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuYLvbjvdFW4"
      },
      "source": [
        "import seaborn as sns\n",
        "sns.lineplot(data=history.history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sv2gfBqa_YgC"
      },
      "source": [
        "#evaluate on the test dataset:\n",
        "autoencoder.evaluate(x_test,y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inspect the reconstructed images"
      ],
      "metadata": {
        "id": "eNXCzH1ReAb8"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjL4QG1ehZbU"
      },
      "source": [
        "# run inference to get reconstructed outputs\n",
        "reconst = autoencoder.predict(x_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vbt14NUvioAH"
      },
      "source": [
        "# make a quick function to plot images in a MxN\n",
        "\n",
        "def plot_mnist_compare(img_tuple,num_cols=10):\n",
        "  base_size=1\n",
        "  M=len(img_tuple)\n",
        "  N=num_cols\n",
        "  fig, axs = plt.subplots(M,N,figsize=(base_size*N,base_size*M))\n",
        "\n",
        "  for i,img in enumerate(img_tuple):\n",
        "    for j in range(N):\n",
        "      axs[i,j].imshow(img[j,:,:,0])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thgBLQasiZ1O"
      },
      "source": [
        "# call the function to plot\n",
        "plot_mnist_compare((x_test,reconst))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wnkq2v9pS9XU"
      },
      "source": [
        "## Inspect the encoded representations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbEFzTHGN4iS"
      },
      "source": [
        "#run samples through the encoder only:\n",
        "encoded = encoder.predict(x_test)\n",
        "encoded.shape\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define a quick function to visualize a scatter plot\n",
        "\n",
        "def plot_latent_2d(latent, class_labels):\n",
        "  fig, axs = plt.subplots(figsize=(10,10))\n",
        "  #loop over each digit class in mnist, plot with a number marker\n",
        "  for i in range(9):\n",
        "    latent_i = latent[class_labels==i]\n",
        "    axs.scatter(latent_i[:,0],latent_i[:,1],marker=f'${i}$',s=50)\n"
      ],
      "metadata": {
        "id": "EvFS7Gvdjh3e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_latent_2d(encoded,y_label_test)"
      ],
      "metadata": {
        "id": "nY3ptz6lgAVD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Try changing the network to see the difference in encoded representations"
      ],
      "metadata": {
        "id": "P3y0hSMnhttw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Denoising Autoencoder"
      ],
      "metadata": {
        "id": "n8IEnM76cfBl"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLPrQDOy2iC4"
      },
      "source": [
        "## Adding noise\n",
        "\n",
        "Here, in addition to applying preprocessing as in past demos, we will also add random noise to all images. We will then treat these corrupted images in the network input, x, and the original image as the network outputs, y. The class labels will not be used at all."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0sDC8BhuBkuC"
      },
      "source": [
        "# corrupt the input images\n",
        "noise_fac = 0.4\n",
        "x_train = y_train + noise_fac * np.random.normal(size=y_train.shape)\n",
        "x_test = y_test + noise_fac * np.random.normal(size=y_test.shape)\n",
        "\n",
        "#clip to ensure still in 0-1 range\n",
        "x_train = np.clip(x_train,0,1)\n",
        "x_test = np.clip(x_test,0,1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aH9cQgF9TQyF"
      },
      "source": [
        "## Examine the data before and after adding noise:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aghzeSw6duKx"
      },
      "source": [
        "plot_mnist_compare((x_test,y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izGDykD5i9nr"
      },
      "source": [
        "## Define the AutoEncoder network\n",
        "\n",
        "Copy the autoencoder already defined here, and adapt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fozupa2Qi9ns"
      },
      "source": [
        "# Compile the model\n",
        "loss = keras.losses.mean_squared_error\n",
        "optim = keras.optimizers.Adam()\n",
        "metric = keras.metrics.mean_squared_error\n",
        "\n",
        "autoencoder.compile(loss=loss,\n",
        "                    optimizer=optim,\n",
        "                    metrics=metric )\n",
        "\n",
        "# What does the finished model look like?\n",
        "autoencoder.summary()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2gQnHaIFi9nu"
      },
      "source": [
        "## Train the network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wO10Pu8i9nv"
      },
      "source": [
        "#fit the model\n",
        "history = autoencoder.fit(x_train,y_train,\n",
        "            batch_size=batch_size,\n",
        "            validation_split=val_split,\n",
        "            epochs=epochs,\n",
        "            steps_per_epoch=steps_per_epoch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXDm0mlMi9nw"
      },
      "source": [
        "#evaluate on the test dataset:\n",
        "autoencoder.evaluate(x_test,y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inspect the reconstructed images"
      ],
      "metadata": {
        "id": "h-T71Kc8i9nx"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kbjHigFYi9nx"
      },
      "source": [
        "# run inference to get reconstructed outputs\n",
        "reconst = autoencoder.predict(x_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_mnist_compare((x_test,y_test,reconst))"
      ],
      "metadata": {
        "id": "bG4MX6q5jrnq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bonus: Compare autoencoder to PCA?\n"
      ],
      "metadata": {
        "id": "YNuIY3GGm2tz"
      }
    }
  ]
}